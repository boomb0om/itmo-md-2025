{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto Data Analysis - ITMO MD 2025\n",
    "\n",
    "–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –∏–∑ Data Mart —Å–ª–æ—è.\n",
    "\n",
    "**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö:**\n",
    "- `dm.dm_crypto_market_overview` - –æ–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Å —Ü–µ–Ω–∞–º–∏, MA, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é\n",
    "- `dm.dm_news_impact_analysis` - –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—ã\n",
    "- `ods.ods_binance_daily_agg` - –¥–Ω–µ–≤–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã —Ü–µ–Ω\n",
    "- `ods.ods_news_enriched` - –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç—ã\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL\n",
    "conn_params = {\n",
    "    'host': '213.171.30.141',\n",
    "    'port': 5433,\n",
    "    'database': 'analytics',\n",
    "    'user': 'analytics',\n",
    "    'password': 'analytics'\n",
    "}\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n",
    "conn = psycopg2.connect(**conn_params)\n",
    "print(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "def query_to_df(sql):\n",
    "    \"\"\"–í—ã–ø–æ–ª–Ω–∏—Ç—å SQL –∑–∞–ø—Ä–æ—Å –∏ –≤–µ—Ä–Ω—É—Ç—å DataFrame\"\"\"\n",
    "    return pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. –ö–∞–∫ –º—ã —Å–æ–±–∏—Ä–∞–µ–º Sentiment?\n",
    "\n",
    "### –ú–µ—Ç–æ–¥: Keyword-based Sentiment Analysis\n",
    "\n",
    "Sentiment –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ DBT –º–æ–¥–µ–ª–∏ `ods_news_enriched` —á–µ—Ä–µ–∑ keyword matching:\n",
    "\n",
    "```sql\n",
    "case\n",
    "    when lower(title) similar to '%(bull|bullish|surge|rally|gain|up|rise|positive)%' \n",
    "        then 'positive'\n",
    "    when lower(title) similar to '%(bear|bearish|crash|fall|drop|down|decline|negative)%' \n",
    "        then 'negative'\n",
    "    else 'neutral'\n",
    "end as sentiment\n",
    "```\n",
    "\n",
    "**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:**\n",
    "- üü¢ **Positive**: bull, bullish, surge, rally, gain, up, rise, positive\n",
    "- üî¥ **Negative**: bear, bearish, crash, fall, drop, down, decline, negative\n",
    "- ‚ö™ **Neutral**: –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ\n",
    "\n",
    "–ó–∞—Ç–µ–º –≤ `dm.dm_news_impact_analysis` –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç—Å—è –ø–æ –¥–∞—Ç–∞–º:\n",
    "```sql\n",
    "count(case when sentiment = 'positive' then 1 end) as positive_news,\n",
    "count(case when sentiment = 'negative' then 1 end) as negative_news,\n",
    "avg(case when sentiment = 'positive' then 1.0 \n",
    "         when sentiment = 'negative' then -1.0 \n",
    "         else 0.0 end) as sentiment_score\n",
    "```\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä—ã –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏—Ö sentiment\n",
    "news_examples = query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        title,\n",
    "        sentiment,\n",
    "        pub_date_only as date\n",
    "    FROM ods.ods_news_enriched\n",
    "    ORDER BY pub_date DESC\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== –ü–†–ò–ú–ï–†–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò SENTIMENT ===\")\n",
    "print(\"\\nüü¢ POSITIVE –Ω–æ–≤–æ—Å—Ç–∏:\")\n",
    "positive_examples = news_examples[news_examples['sentiment'] == 'positive']\n",
    "for idx, row in positive_examples.head(3).iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['title'][:80]}...\")\n",
    "\n",
    "print(\"\\nüî¥ NEGATIVE –Ω–æ–≤–æ—Å—Ç–∏:\")\n",
    "negative_examples = news_examples[news_examples['sentiment'] == 'negative']\n",
    "for idx, row in negative_examples.head(3).iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['title'][:80]}...\")\n",
    "\n",
    "print(\"\\n‚ö™ NEUTRAL –Ω–æ–≤–æ—Å—Ç–∏:\")\n",
    "neutral_examples = news_examples[news_examples['sentiment'] == 'neutral']\n",
    "for idx, row in neutral_examples.head(3).iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['title'][:80]}...\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "print(\"\\n=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê SENTIMENT ===\")\n",
    "sentiment_counts = news_examples['sentiment'].value_counts()\n",
    "print(sentiment_counts)\n",
    "print(f\"\\nTotal: {len(news_examples)} –Ω–æ–≤–æ—Å—Ç–µ–π\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Data Mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±–∑–æ—Ä–∞ —Ä—ã–Ω–∫–∞\n",
    "market_overview = query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        symbol,\n",
    "        last_update_date as date,\n",
    "        current_price,\n",
    "        ma_7d,\n",
    "        ma_30d,\n",
    "        volatility_7d,\n",
    "        trend_indicator,\n",
    "        volume_24h as total_volume,\n",
    "        trades_24h\n",
    "    FROM dm.dm_crypto_market_overview\n",
    "    ORDER BY last_update_date DESC, symbol\n",
    "\"\"\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π\n",
    "news_impact = query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        analysis_date as date,\n",
    "        symbol,\n",
    "        news_count as total_news,\n",
    "        positive_news,\n",
    "        negative_news,\n",
    "        (news_count - positive_news - negative_news) as neutral_news,\n",
    "        sentiment_score as avg_sentiment_score,\n",
    "        price_change_pct as avg_price_change_pct,\n",
    "        sentiment_price_correlation\n",
    "    FROM dm.dm_news_impact_analysis\n",
    "    ORDER BY analysis_date DESC\n",
    "\"\"\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–Ω–µ–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "daily_agg = query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        symbol,\n",
    "        trade_date as date,\n",
    "        daily_open as open_price,\n",
    "        daily_close as close_price,\n",
    "        daily_high as high_price,\n",
    "        daily_low as low_price,\n",
    "        daily_volume as total_volume,\n",
    "        price_change_pct,\n",
    "        volatility\n",
    "    FROM ods.ods_binance_daily_agg\n",
    "    ORDER BY trade_date DESC, symbol\n",
    "\"\"\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å sentiment\n",
    "news_enriched = query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        pub_date_only as date,\n",
    "        title,\n",
    "        sentiment,\n",
    "        title_length,\n",
    "        description_length,\n",
    "        categories_count\n",
    "    FROM ods.ods_news_enriched\n",
    "    ORDER BY pub_date DESC\n",
    "    LIMIT 1000\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ:\")\n",
    "print(f\"   - Market Overview: {len(market_overview)} —Å—Ç—Ä–æ–∫ (symbols: {market_overview['symbol'].nunique()})\")\n",
    "print(f\"   - News Impact: {len(news_impact)} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   - Daily Aggregates: {len(daily_agg)} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   - News Enriched: {len(news_enriched)} —Å—Ç—Ä–æ–∫\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ date range\n",
    "if len(market_overview) > 0:\n",
    "    print(f\"\\nüìÖ Date Range Market: {market_overview['date'].min()} ‚Üí {market_overview['date'].max()}\")\n",
    "if len(news_enriched) > 0:\n",
    "    print(f\"üìÖ Date Range News: {news_enriched['date'].min()} ‚Üí {news_enriched['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 1: Snapshot —Ä—ã–Ω–∫–∞ (Current State)\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä—ã–Ω–∫–∞ - —Ü–µ–Ω—ã, —Ç—Ä–µ–Ω–¥—ã, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(market_overview) > 0:\n",
    "    # –ü–æ—Å–ª–µ–¥–Ω–∏–π snapshot –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞\n",
    "    latest_market = market_overview.sort_values('date').groupby('symbol').tail(1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. –¢–µ–∫—É—â–∏–µ —Ü–µ–Ω—ã\n",
    "    ax1 = axes[0, 0]\n",
    "    bars1 = ax1.barh(latest_market['symbol'], latest_market['current_price'], color='steelblue')\n",
    "    ax1.set_xlabel('Price (USDT)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Current Prices by Symbol', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (price, symbol) in enumerate(zip(latest_market['current_price'], latest_market['symbol'])):\n",
    "        ax1.text(price, i, f' ${price:,.2f}', va='center', fontsize=9)\n",
    "    \n",
    "    # 2. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å 7d\n",
    "    ax2 = axes[0, 1]\n",
    "    colors = ['red' if v > 0.05 else 'orange' if v > 0.03 else 'green' \n",
    "              for v in latest_market['volatility_7d']]\n",
    "    bars2 = ax2.barh(latest_market['symbol'], latest_market['volatility_7d'], color=colors)\n",
    "    ax2.set_xlabel('7-Day Volatility', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Volatility Risk Profile', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (vol, symbol) in enumerate(zip(latest_market['volatility_7d'], latest_market['symbol'])):\n",
    "        ax2.text(vol, i, f' {vol:.4f}', va='center', fontsize=9)\n",
    "    \n",
    "    # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤\n",
    "    ax3 = axes[1, 0]\n",
    "    trend_counts = latest_market['trend_indicator'].value_counts()\n",
    "    colors_trend = {'uptrend': 'green', 'downtrend': 'red', 'sideways': 'gray'}\n",
    "    ax3.pie(trend_counts.values, labels=trend_counts.index, autopct='%1.1f%%',\n",
    "            colors=[colors_trend.get(t, 'blue') for t in trend_counts.index],\n",
    "            startangle=90)\n",
    "    ax3.set_title('Market Trend Distribution', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 4. MA Position (Price vs MA7 vs MA30)\n",
    "    ax4 = axes[1, 1]\n",
    "    x = np.arange(len(latest_market))\n",
    "    width = 0.25\n",
    "    ax4.bar(x - width, latest_market['current_price'], width, label='Current Price', color='blue')\n",
    "    ax4.bar(x, latest_market['ma_7d'], width, label='MA 7d', color='orange')\n",
    "    ax4.bar(x + width, latest_market['ma_30d'], width, label='MA 30d', color='green')\n",
    "    ax4.set_xlabel('Symbol', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Price (USDT)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Price Position vs Moving Averages', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels(latest_market['symbol'])\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # –ò–Ω—Å–∞–π—Ç—ã\n",
    "    print(\"\\nüìä –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï –†–´–ù–ö–ê:\")\n",
    "    for idx, row in latest_market.iterrows():\n",
    "        print(f\"\\n{row['symbol']}:\")\n",
    "        print(f\"   üí∞ –¶–µ–Ω–∞: ${row['current_price']:,.2f}\")\n",
    "        print(f\"   üìà –¢—Ä–µ–Ω–¥: {row['trend_indicator']}\")\n",
    "        print(f\"   üìä –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (7d): {row['volatility_7d']:.4f}\")\n",
    "        print(f\"   üìâ MA(7): ${row['ma_7d']:,.2f} | MA(30): ${row['ma_30d']:,.2f}\")\n",
    "        \n",
    "        if row['current_price'] > row['ma_7d'] > row['ma_30d']:\n",
    "            print(\"   ‚úÖ –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (Price > MA7 > MA30)\")\n",
    "        elif row['current_price'] < row['ma_7d'] < row['ma_30d']:\n",
    "            print(\"   ‚ö†Ô∏è –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (Price < MA7 < MA30)\")\n",
    "        else:\n",
    "            print(\"   ‚ö° –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∏–ª–∏ —Ä–∞–∑–≤–æ—Ä–æ—Ç —Ç—Ä–µ–Ω–¥–∞\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 2: Sentiment Distribution\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ sentiment –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä—ã–Ω–æ–∫."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(news_enriched) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. –û–±—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ sentiment\n",
    "    ax1 = axes[0, 0]\n",
    "    sentiment_counts = news_enriched['sentiment'].value_counts()\n",
    "    colors_sent = {'positive': 'green', 'negative': 'red', 'neutral': 'gray'}\n",
    "    ax1.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
    "            colors=[colors_sent.get(s, 'blue') for s in sentiment_counts.index],\n",
    "            startangle=90, explode=[0.05]*len(sentiment_counts))\n",
    "    ax1.set_title('Overall News Sentiment Distribution', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 2. Sentiment –ø–æ –¥–Ω—è–º (—Ç–æ–ø-10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–Ω–µ–π)\n",
    "    ax2 = axes[0, 1]\n",
    "    daily_sentiment = news_enriched.groupby(['date', 'sentiment']).size().unstack(fill_value=0)\n",
    "    daily_sentiment = daily_sentiment.sort_index(ascending=False).head(10).sort_index()\n",
    "    \n",
    "    if 'positive' in daily_sentiment.columns:\n",
    "        ax2.bar(range(len(daily_sentiment)), daily_sentiment['positive'], \n",
    "                label='Positive', color='green', alpha=0.7)\n",
    "    bottom = daily_sentiment.get('positive', 0)\n",
    "    if 'negative' in daily_sentiment.columns:\n",
    "        ax2.bar(range(len(daily_sentiment)), daily_sentiment['negative'],\n",
    "                bottom=bottom, label='Negative', color='red', alpha=0.7)\n",
    "        bottom = bottom + daily_sentiment['negative']\n",
    "    if 'neutral' in daily_sentiment.columns:\n",
    "        ax2.bar(range(len(daily_sentiment)), daily_sentiment['neutral'],\n",
    "                bottom=bottom, label='Neutral', color='gray', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Date', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of News', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Daily Sentiment Distribution (Last 10 Days)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xticks(range(len(daily_sentiment)))\n",
    "    ax2.set_xticklabels([d.strftime('%m-%d') for d in daily_sentiment.index], rotation=45)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –ø–æ sentiment\n",
    "    ax3 = axes[1, 0]\n",
    "    news_enriched.boxplot(column='title_length', by='sentiment', ax=ax3, patch_artist=True)\n",
    "    ax3.set_xlabel('Sentiment', fontsize=11, fontweight='bold')\n",
    "    ax3.set_ylabel('Title Length (characters)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Title Length Distribution by Sentiment', fontsize=12, fontweight='bold')\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # 4. Sentiment vs Price Change (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
    "    ax4 = axes[1, 1]\n",
    "    if len(news_impact) > 0:\n",
    "        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º\n",
    "        news_agg = news_impact.groupby('date').agg({\n",
    "            'avg_sentiment_score': 'mean',\n",
    "            'avg_price_change_pct': 'mean'\n",
    "        }).reset_index().sort_values('date')\n",
    "        \n",
    "        ax4.scatter(news_agg['avg_sentiment_score'], news_agg['avg_price_change_pct'],\n",
    "                   s=100, alpha=0.6, c=range(len(news_agg)), cmap='viridis')\n",
    "        \n",
    "        # –õ–∏–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞\n",
    "        if len(news_agg) > 1:\n",
    "            z = np.polyfit(news_agg['avg_sentiment_score'], news_agg['avg_price_change_pct'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax4.plot(news_agg['avg_sentiment_score'], \n",
    "                    p(news_agg['avg_sentiment_score']), \n",
    "                    \"r--\", alpha=0.8, linewidth=2, label='Trend')\n",
    "        \n",
    "        ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax4.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax4.set_xlabel('Sentiment Score', fontsize=11, fontweight='bold')\n",
    "        ax4.set_ylabel('Price Change %', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title('Sentiment vs Price Change Correlation', fontsize=12, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.legend()\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No correlation data available', \n",
    "                ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "        ax4.set_title('Sentiment vs Price Change (No Data)', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # –ò–Ω—Å–∞–π—Ç—ã\n",
    "    print(\"\\nüìä SENTIMENT ANALYSIS INSIGHTS:\")\n",
    "    total = len(news_enriched)\n",
    "    print(f\"\\n   –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total}\")\n",
    "    for sentiment, count in sentiment_counts.items():\n",
    "        emoji = {'positive': 'üü¢', 'negative': 'üî¥', 'neutral': '‚ö™'}.get(sentiment, '‚Ä¢')\n",
    "        print(f\"   {emoji} {sentiment.capitalize()}: {count} ({count/total*100:.1f}%)\")\n",
    "    \n",
    "    if len(news_impact) > 0:\n",
    "        positive_corr = (news_impact['sentiment_price_correlation'] == 'positive_correlation').sum()\n",
    "        negative_corr = (news_impact['sentiment_price_correlation'] == 'negative_correlation').sum()\n",
    "        no_corr = (news_impact['sentiment_price_correlation'] == 'no_correlation').sum()\n",
    "        total_days = len(news_impact)\n",
    "        \n",
    "        print(f\"\\n   üìà –î–Ω–µ–π —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π: {positive_corr} ({positive_corr/total_days*100:.1f}%)\")\n",
    "        print(f\"   üìâ –î–Ω–µ–π —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π: {negative_corr} ({negative_corr/total_days*100:.1f}%)\")\n",
    "        print(f\"   ‚ûñ –î–Ω–µ–π –±–µ–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {no_corr} ({no_corr/total_days*100:.1f}%)\")\n",
    "        \n",
    "        if positive_corr > total_days / 2:\n",
    "            print(\"\\n   ‚úÖ Sentiment –Ω–æ–≤–æ—Å—Ç–µ–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º —Ü–µ–Ω\")\n",
    "        else:\n",
    "            print(\"\\n   ‚ö†Ô∏è Sentiment –Ω–æ–≤–æ—Å—Ç–µ–π —Å–ª–∞–±–æ —Å–≤—è–∑–∞–Ω —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º —Ü–µ–Ω\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 3: OHLC Candlestick Analysis\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–≤–µ—á–µ–π –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏ —Ü–µ–Ω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily_agg) > 0:\n",
    "    # –í–∑—è—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞\n",
    "    symbols_available = daily_agg['symbol'].unique()\n",
    "    selected_symbol = symbols_available[0]\n",
    "    \n",
    "    candle_data = daily_agg[daily_agg['symbol'] == selected_symbol].sort_values('date')\n",
    "    \n",
    "    if len(candle_data) > 0:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=True)\n",
    "        \n",
    "        # –ì—Ä–∞—Ñ–∏–∫ 1: Candlestick\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        up = candle_data[candle_data['close_price'] >= candle_data['open_price']]\n",
    "        down = candle_data[candle_data['close_price'] < candle_data['open_price']]\n",
    "        \n",
    "        # –ó–µ–ª–µ–Ω—ã–µ —Å–≤–µ—á–∏ (—Ä–æ—Å—Ç)\n",
    "        for idx, row in up.iterrows():\n",
    "            x_pos = list(candle_data.index).index(idx)\n",
    "            # –¢–µ–ª–æ —Å–≤–µ—á–∏\n",
    "            ax1.bar(x_pos, row['close_price'] - row['open_price'], \n",
    "                   bottom=row['open_price'], color='green', alpha=0.8, width=0.6)\n",
    "            # –¢–µ–Ω–∏\n",
    "            ax1.plot([x_pos, x_pos], [row['low_price'], row['high_price']], \n",
    "                    color='green', linewidth=1, alpha=0.8)\n",
    "        \n",
    "        # –ö—Ä–∞—Å–Ω—ã–µ —Å–≤–µ—á–∏ (–ø–∞–¥–µ–Ω–∏–µ)\n",
    "        for idx, row in down.iterrows():\n",
    "            x_pos = list(candle_data.index).index(idx)\n",
    "            # –¢–µ–ª–æ —Å–≤–µ—á–∏\n",
    "            ax1.bar(x_pos, row['open_price'] - row['close_price'], \n",
    "                   bottom=row['close_price'], color='red', alpha=0.8, width=0.6)\n",
    "            # –¢–µ–Ω–∏\n",
    "            ax1.plot([x_pos, x_pos], [row['low_price'], row['high_price']], \n",
    "                    color='red', linewidth=1, alpha=0.8)\n",
    "        \n",
    "        ax1.set_ylabel('Price (USDT)', fontsize=11, fontweight='bold')\n",
    "        ax1.set_title(f'{selected_symbol} Candlestick Chart', fontsize=13, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # –ì—Ä–∞—Ñ–∏–∫ 2: –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤\n",
    "        ax2 = axes[1]\n",
    "        colors = ['green' if row['close_price'] >= row['open_price'] else 'red' \n",
    "                 for idx, row in candle_data.iterrows()]\n",
    "        ax2.bar(range(len(candle_data)), candle_data['total_volume'], \n",
    "               color=colors, alpha=0.7)\n",
    "        ax2.set_xlabel('Date', fontsize=11, fontweight='bold')\n",
    "        ax2.set_ylabel('Volume', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Trading Volume (Green = Price Up, Red = Price Down)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # X-axis labels\n",
    "        ax2.set_xticks(range(len(candle_data)))\n",
    "        ax2.set_xticklabels([d.strftime('%Y-%m-%d') for d in candle_data['date']], \n",
    "                           rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # –ò–Ω—Å–∞–π—Ç—ã\n",
    "        print(f\"\\nüìä CANDLESTICK ANALYSIS –¥–ª—è {selected_symbol}:\")\n",
    "        print(f\"\\n   –ü–µ—Ä–∏–æ–¥: {candle_data['date'].min()} ‚Üí {candle_data['date'].max()}\")\n",
    "        print(f\"   –í—Å–µ–≥–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π: {len(candle_data)}\")\n",
    "        print(f\"\\n   üí∞ –¶–µ–Ω—ã:\")\n",
    "        print(f\"      –ú–∏–Ω–∏–º—É–º: ${candle_data['low_price'].min():,.2f}\")\n",
    "        print(f\"      –ú–∞–∫—Å–∏–º—É–º: ${candle_data['high_price'].max():,.2f}\")\n",
    "        print(f\"      –¢–µ–∫—É—â–∞—è: ${candle_data.iloc[-1]['close_price']:,.2f}\")\n",
    "        \n",
    "        up_days = len(up)\n",
    "        down_days = len(down)\n",
    "        print(f\"\\n   üìà –¢–æ—Ä–≥–æ–≤—ã–µ –¥–Ω–∏:\")\n",
    "        print(f\"      –ó–µ–ª–µ–Ω—ã–µ (—Ä–æ—Å—Ç): {up_days} ({up_days/len(candle_data)*100:.1f}%)\")\n",
    "        print(f\"      –ö—Ä–∞—Å–Ω—ã–µ (–ø–∞–¥–µ–Ω–∏–µ): {down_days} ({down_days/len(candle_data)*100:.1f}%)\")\n",
    "        \n",
    "        avg_volatility = candle_data['volatility'].mean()\n",
    "        print(f\"\\n   üìä –°—Ä–µ–¥–Ω—è—è –¥–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {avg_volatility:.4f}\")\n",
    "        \n",
    "        max_gain = candle_data['price_change_pct'].max()\n",
    "        max_loss = candle_data['price_change_pct'].min()\n",
    "        print(f\"   üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç –∑–∞ –¥–µ–Ω—å: {max_gain:.2f}%\")\n",
    "        print(f\"   üìâ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ –∑–∞ –¥–µ–Ω—å: {max_loss:.2f}%\")\n",
    "        \n",
    "        # Volume analysis\n",
    "        avg_volume = candle_data['total_volume'].mean()\n",
    "        max_volume = candle_data['total_volume'].max()\n",
    "        max_volume_date = candle_data[candle_data['total_volume'] == max_volume]['date'].iloc[0]\n",
    "        print(f\"\\n   üì¶ –û–±—ä–µ–º—ã:\")\n",
    "        print(f\"      –°—Ä–µ–¥–Ω–∏–π: {avg_volume:,.0f}\")\n",
    "        print(f\"      –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max_volume:,.0f} (–¥–∞—Ç–∞: {max_volume_date})\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {selected_symbol}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ—Ç OHLC –¥–∞–Ω–Ω—ã—Ö\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 4: Correlation Heatmap\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –í–∑–∞–∏–º–æ—Å–≤—è–∑—å –º–µ–∂–¥—É —Ü–µ–Ω–æ–π, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é, –æ–±—ä–µ–º–æ–º –∏ sentiment –Ω–æ–≤–æ—Å—Ç–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "correlation_data = pd.DataFrame()\n",
    "\n",
    "if len(market_overview) > 0:\n",
    "    market_for_corr = market_overview[['symbol', 'date', 'current_price', \n",
    "                                       'volatility_7d', 'total_volume']]\n",
    "    correlation_data = market_for_corr.copy()\n",
    "\n",
    "if len(news_impact) > 0:\n",
    "    news_for_corr = news_impact[['symbol', 'date', 'avg_sentiment_score', 'total_news']]\n",
    "    \n",
    "    if len(correlation_data) > 0:\n",
    "        correlation_data = pd.merge(correlation_data, news_for_corr, \n",
    "                                   on=['symbol', 'date'], how='left')\n",
    "    else:\n",
    "        correlation_data = news_for_corr.copy()\n",
    "\n",
    "if len(correlation_data) > 0:\n",
    "    # –û—Ç–æ–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    numeric_cols = correlation_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = correlation_data[numeric_cols].corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm',\n",
    "                   center=0, square=True, linewidths=1, \n",
    "                   cbar_kws={\"shrink\": 0.8}, ax=ax,\n",
    "                   vmin=-1, vmax=1)\n",
    "        \n",
    "        ax.set_title('Correlation Matrix: Market Metrics', \n",
    "                    fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # –ò–Ω—Å–∞–π—Ç—ã\n",
    "        print(\"\\nüìä –ö–õ–Æ–ß–ï–í–´–ï –ö–û–†–†–ï–õ–Ø–¶–ò–ò:\")\n",
    "        print(\"\\n–°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (|r| > 0.5):\")\n",
    "        \n",
    "        strong_corr_found = False\n",
    "        for i in range(len(corr_matrix)):\n",
    "            for j in range(i+1, len(corr_matrix)):\n",
    "                corr_value = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_value) > 0.5:\n",
    "                    col1 = corr_matrix.index[i]\n",
    "                    col2 = corr_matrix.columns[j]\n",
    "                    direction = \"–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è\" if corr_value > 0 else \"–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è\"\n",
    "                    strength = \"—Å–∏–ª—å–Ω–∞—è\" if abs(corr_value) > 0.7 else \"—É–º–µ—Ä–µ–Ω–Ω–∞—è\"\n",
    "                    print(f\"   ‚Ä¢ {col1} ‚Üî {col2}: {strength} {direction} ({corr_value:.3f})\")\n",
    "                    strong_corr_found = True\n",
    "        \n",
    "        if not strong_corr_found:\n",
    "            print(\"   –ù–µ—Ç —Å–∏–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (|r| > 0.5)\")\n",
    "        \n",
    "        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "        if 'avg_sentiment_score' in corr_matrix and 'current_price' in corr_matrix:\n",
    "            sent_price_corr = corr_matrix.loc['avg_sentiment_score', 'current_price']\n",
    "            print(f\"\\n   üì∞ Sentiment ‚Üî Price: {sent_price_corr:.3f}\")\n",
    "            if abs(sent_price_corr) > 0.3:\n",
    "                print(\"      ‚úÖ –ó–∞–º–µ—Ç–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—É\")\n",
    "            else:\n",
    "                print(\"      ‚ö†Ô∏è –°–ª–∞–±–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—É\")\n",
    "        \n",
    "        if 'total_volume' in corr_matrix and 'volatility_7d' in corr_matrix:\n",
    "            vol_volat_corr = corr_matrix.loc['total_volume', 'volatility_7d']\n",
    "            print(f\"\\n   üìä Volume ‚Üî Volatility: {vol_volat_corr:.3f}\")\n",
    "            if vol_volat_corr > 0.3:\n",
    "                print(\"      ‚úÖ –í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º —Å–≤—è–∑–∞–Ω —Å –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 5: Time Series Patterns (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ü–µ–Ω–∞—Ö –∏ –Ω–æ–≤–æ—Å—Ç—è—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily_agg) > 1 or len(news_enriched) > 10:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    \n",
    "    # –ì—Ä–∞—Ñ–∏–∫ 1: Price trends\n",
    "    ax1 = axes[0]\n",
    "    if len(daily_agg) > 1:\n",
    "        for symbol in daily_agg['symbol'].unique():\n",
    "            symbol_data = daily_agg[daily_agg['symbol'] == symbol].sort_values('date')\n",
    "            ax1.plot(symbol_data['date'], symbol_data['close_price'], \n",
    "                    marker='o', label=symbol, linewidth=2)\n",
    "        \n",
    "        ax1.set_xlabel('Date', fontsize=11, fontweight='bold')\n",
    "        ax1.set_ylabel('Close Price (USDT)', fontsize=11, fontweight='bold')\n",
    "        ax1.set_title('Price Trends Over Time', fontsize=12, fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'Insufficient price data for time series', \n",
    "                ha='center', va='center', transform=ax1.transAxes, fontsize=12)\n",
    "    \n",
    "    # –ì—Ä–∞—Ñ–∏–∫ 2: News frequency over time\n",
    "    ax2 = axes[1]\n",
    "    if len(news_enriched) > 10:\n",
    "        news_daily_count = news_enriched.groupby('date').size().reset_index(name='count')\n",
    "        news_daily_count = news_daily_count.sort_values('date')\n",
    "        \n",
    "        ax2.bar(news_daily_count['date'], news_daily_count['count'], \n",
    "               alpha=0.7, color='steelblue')\n",
    "        ax2.set_xlabel('Date', fontsize=11, fontweight='bold')\n",
    "        ax2.set_ylabel('Number of News', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('News Frequency Over Time', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Insufficient news data for time series', \n",
    "                ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä TIME SERIES INSIGHTS:\")\n",
    "    if len(daily_agg) > 1:\n",
    "        print(f\"\\n   üìà –î–æ—Å—Ç—É–ø–Ω–æ {len(daily_agg)} —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π\")\n",
    "        print(f\"   üìÖ –ü–µ—Ä–∏–æ–¥: {daily_agg['date'].min()} ‚Üí {daily_agg['date'].max()}\")\n",
    "    \n",
    "    if len(news_enriched) > 10:\n",
    "        news_per_day = len(news_enriched) / news_enriched['date'].nunique()\n",
    "        print(f\"\\n   üì∞ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–µ–Ω—å: {news_per_day:.1f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\")\n",
    "    print(\"   –î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –±–æ–ª—å—à–∏–π –ø–µ—Ä–∏–æ–¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 6: Summary Dashboard\n",
    "\n",
    "**–ò–Ω—Å–∞–π—Ç**: –°–≤–æ–¥–Ω–∞—è –ø–∞–Ω–µ–ª—å —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# 1. –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Ç–µ–∫—Å—Ç)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.axis('off')\n",
    "\n",
    "metrics_text = \"=\" * 80 + \"\\n\"\n",
    "metrics_text += \"CRYPTO MARKET SUMMARY DASHBOARD\\n\"\n",
    "metrics_text += \"=\" * 80 + \"\\n\\n\"\n",
    "\n",
    "if len(market_overview) > 0:\n",
    "    latest = market_overview.sort_values('date').groupby('symbol').tail(1)\n",
    "    metrics_text += \"üìä MARKET OVERVIEW:\\n\"\n",
    "    for idx, row in latest.iterrows():\n",
    "        metrics_text += f\"   {row['symbol']}: ${row['current_price']:,.2f} | \"\n",
    "        metrics_text += f\"Trend: {row['trend_indicator']} | Vol: {row['volatility_7d']:.4f}\\n\"\n",
    "\n",
    "if len(news_enriched) > 0:\n",
    "    sentiment_dist = news_enriched['sentiment'].value_counts()\n",
    "    total_news = len(news_enriched)\n",
    "    metrics_text += f\"\\nüì∞ NEWS SENTIMENT ({total_news} articles):\\n\"\n",
    "    for sent, count in sentiment_dist.items():\n",
    "        emoji = {'positive': 'üü¢', 'negative': 'üî¥', 'neutral': '‚ö™'}.get(sent, '‚Ä¢')\n",
    "        metrics_text += f\"   {emoji} {sent.capitalize()}: {count} ({count/total_news*100:.1f}%)\\n\"\n",
    "\n",
    "if len(daily_agg) > 0:\n",
    "    metrics_text += f\"\\nüìà TRADING DATA:\\n\"\n",
    "    metrics_text += f\"   Total trading days: {len(daily_agg)}\\n\"\n",
    "    metrics_text += f\"   Date range: {daily_agg['date'].min()} ‚Üí {daily_agg['date'].max()}\\n\"\n",
    "\n",
    "ax1.text(0.05, 0.95, metrics_text, transform=ax1.transAxes,\n",
    "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# 2-4. –ú–∏–Ω–∏-–≥—Ä–∞—Ñ–∏–∫–∏\n",
    "if len(market_overview) > 0:\n",
    "    # Current prices\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    latest = market_overview.sort_values('date').groupby('symbol').tail(1)\n",
    "    ax2.barh(latest['symbol'], latest['current_price'], color='steelblue')\n",
    "    ax2.set_xlabel('Price (USDT)', fontsize=9)\n",
    "    ax2.set_title('Current Prices', fontsize=10, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "if len(news_enriched) > 0:\n",
    "    # Sentiment pie\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    sentiment_counts = news_enriched['sentiment'].value_counts()\n",
    "    colors_sent = [{'positive': 'green', 'negative': 'red', 'neutral': 'gray'}.get(s, 'blue') \n",
    "                  for s in sentiment_counts.index]\n",
    "    ax3.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.0f%%',\n",
    "           colors=colors_sent, startangle=90)\n",
    "    ax3.set_title('Sentiment Distribution', fontsize=10, fontweight='bold')\n",
    "\n",
    "if len(market_overview) > 0:\n",
    "    # Volatility\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "    latest = market_overview.sort_values('date').groupby('symbol').tail(1)\n",
    "    colors_vol = ['red' if v > 0.05 else 'orange' if v > 0.03 else 'green' \n",
    "                 for v in latest['volatility_7d']]\n",
    "    ax4.barh(latest['symbol'], latest['volatility_7d'], color=colors_vol)\n",
    "    ax4.set_xlabel('7d Volatility', fontsize=9)\n",
    "    ax4.set_title('Volatility Risk', fontsize=10, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 5-7. Bottom row\n",
    "if len(daily_agg) > 0:\n",
    "    # Price trend\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    for symbol in daily_agg['symbol'].unique()[:3]:  # Max 3 symbols\n",
    "        symbol_data = daily_agg[daily_agg['symbol'] == symbol].sort_values('date')\n",
    "        ax5.plot(symbol_data['date'], symbol_data['close_price'], \n",
    "                marker='o', label=symbol, linewidth=1.5)\n",
    "    ax5.set_xlabel('Date', fontsize=9)\n",
    "    ax5.set_ylabel('Price', fontsize=9)\n",
    "    ax5.set_title('Price Trends', fontsize=10, fontweight='bold')\n",
    "    ax5.legend(fontsize=8)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, fontsize=8)\n",
    "\n",
    "if len(news_enriched) > 5:\n",
    "    # News frequency\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    news_daily = news_enriched.groupby('date').size().reset_index(name='count')\n",
    "    news_daily = news_daily.sort_values('date').tail(10)\n",
    "    ax6.bar(range(len(news_daily)), news_daily['count'], color='steelblue', alpha=0.7)\n",
    "    ax6.set_xlabel('Date', fontsize=9)\n",
    "    ax6.set_ylabel('News Count', fontsize=9)\n",
    "    ax6.set_title('News Frequency', fontsize=10, fontweight='bold')\n",
    "    ax6.set_xticks(range(len(news_daily)))\n",
    "    ax6.set_xticklabels([d.strftime('%m-%d') for d in news_daily['date']], \n",
    "                       rotation=45, fontsize=8)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "if len(market_overview) > 0:\n",
    "    # Trend distribution\n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    trend_counts = market_overview['trend_indicator'].value_counts()\n",
    "    colors_trend = [{'uptrend': 'green', 'downtrend': 'red', 'sideways': 'gray'}.get(t, 'blue') \n",
    "                   for t in trend_counts.index]\n",
    "    ax7.bar(range(len(trend_counts)), trend_counts.values, color=colors_trend, alpha=0.7)\n",
    "    ax7.set_xticks(range(len(trend_counts)))\n",
    "    ax7.set_xticklabels(trend_counts.index, rotation=45, fontsize=8)\n",
    "    ax7.set_ylabel('Count', fontsize=9)\n",
    "    ax7.set_title('Market Trends', fontsize=10, fontweight='bold')\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Crypto Market Analytics Dashboard', fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dashboard generated successfully!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"–ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ –ú–ï–¢–û–î SENTIMENT ANALYSIS:\")\n",
    "print(\"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è keyword-based –ø–æ–¥—Ö–æ–¥ –≤ DBT\")\n",
    "print(\"   ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: positive / negative / neutral\")\n",
    "print(\"   ‚úÖ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è positive: bull, surge, rally, gain, rise\")\n",
    "print(\"   ‚úÖ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è negative: bear, crash, fall, drop, decline\")\n",
    "print(\"   ‚ö†Ô∏è –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥, –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í:\")\n",
    "if len(market_overview) > 0:\n",
    "    trend_distribution = market_overview['trend_indicator'].value_counts()\n",
    "    dominant_trend = trend_distribution.index[0]\n",
    "    print(f\"   - –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Ç—Ä–µ–Ω–¥: {dominant_trend}\")\n",
    "    for trend, count in trend_distribution.items():\n",
    "        emoji = {'uptrend': 'üìà', 'downtrend': 'üìâ', 'sideways': '‚û°Ô∏è'}.get(trend, '‚Ä¢')\n",
    "        print(f\"   {emoji} {trend}: {count} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ –ò –†–ò–°–ö–ò:\")\n",
    "if len(market_overview) > 0:\n",
    "    vol_stats = market_overview.groupby('symbol')['volatility_7d'].mean().sort_values(ascending=False)\n",
    "    print(\"   –†–µ–π—Ç–∏–Ω–≥ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–æ—Ç –≤—ã—Å–æ–∫–æ–π –∫ –Ω–∏–∑–∫–æ–π):\")\n",
    "    for symbol, vol in vol_stats.items():\n",
    "        risk_level = \"–í–´–°–û–ö–ò–ô\" if vol > 0.05 else \"–°–†–ï–î–ù–ò–ô\" if vol > 0.03 else \"–ù–ò–ó–ö–ò–ô\"\n",
    "        emoji = \"üî¥\" if vol > 0.05 else \"üü°\" if vol > 0.03 else \"üü¢\"\n",
    "        print(f\"   {emoji} {symbol}: {vol:.4f} ({risk_level} —Ä–∏—Å–∫)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ –í–õ–ò–Ø–ù–ò–ï –ù–û–í–û–°–¢–ï–ô:\")\n",
    "if len(news_impact) > 0:\n",
    "    corr_stats = news_impact['sentiment_price_correlation'].value_counts()\n",
    "    total_days = len(news_impact)\n",
    "    \n",
    "    for corr_type, count in corr_stats.items():\n",
    "        pct = count / total_days * 100\n",
    "        emoji = {'positive_correlation': '‚úÖ', \n",
    "                'negative_correlation': '‚ö†Ô∏è', \n",
    "                'no_correlation': '‚ûñ'}.get(corr_type, '‚Ä¢')\n",
    "        print(f\"   {emoji} {corr_type}: {count} –¥–Ω–µ–π ({pct:.1f}%)\")\n",
    "    \n",
    "    positive_pct = corr_stats.get('positive_correlation', 0) / total_days * 100\n",
    "    if positive_pct > 50:\n",
    "        print(\"\\n   ‚úÖ Sentiment –Ω–æ–≤–æ—Å—Ç–µ–π - –Ω–∞–¥–µ–∂–Ω—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω\")\n",
    "    else:\n",
    "        print(\"\\n   ‚ö†Ô∏è Sentiment –Ω–æ–≤–æ—Å—Ç–µ–π —Å–ª–∞–±–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ü–µ–Ω–∞–º–∏\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ –¢–û–†–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\")\n",
    "print(\"   üìä –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã:\")\n",
    "print(\"      ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ MA(7) –∏ MA(30) –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞\")\n",
    "print(\"      ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ sentiment –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª\")\n",
    "print(\"      ‚Ä¢ –ò–∑–±–µ–≥–∞–π—Ç–µ —Ç–æ—Ä–≥–æ–≤–ª–∏ –≤ –ø–µ—Ä–∏–æ–¥—ã —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (>5%)\")\n",
    "print(\"      ‚Ä¢ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–π—Ç–µ —Ü–µ–Ω–æ–≤—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–º –æ–±—ä–µ–º–æ–≤\")\n",
    "print(\"      ‚Ä¢ –î–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –ø–æ—Ä—Ç—Ñ–µ–ª—å –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏ —Å —Ä–∞–∑–Ω–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ –ê–†–•–ò–¢–ï–ö–¢–£–†–ê DATA PIPELINE:\")\n",
    "print(\"   üì¶ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: Binance API + Crypto.news RSS\")\n",
    "print(\"   üîÑ Pipeline: FastAPI ‚Üí MongoDB ‚Üí Airflow EL ‚Üí PostgreSQL\")\n",
    "print(\"   üîß –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: DBT (STG ‚Üí ODS ‚Üí DM)\")\n",
    "print(\"   ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: Elementary monitoring + 57 —Ç–µ—Å—Ç–æ–≤\")\n",
    "print(\"   üìä –ê–Ω–∞–ª–∏–∑: Python + Pandas + Matplotlib + Seaborn\")\n",
    "\n",
    "print(\"\\n7Ô∏è‚É£ –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ò –£–õ–£–ß–®–ï–ù–ò–Ø:\")\n",
    "print(\"   ‚ö†Ô∏è –¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\")\n",
    "print(\"      ‚Ä¢ Keyword-based sentiment (–ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥)\")\n",
    "print(\"      ‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥\")\n",
    "print(\"      ‚Ä¢ –î–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å–∏–º–≤–æ–ª–∞–º\")\n",
    "print(\"\\n   üí° –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:\")\n",
    "print(\"      ‚Ä¢ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è sentiment (BERT, GPT)\")\n",
    "print(\"      ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç\")\n",
    "print(\"      ‚Ä¢ –ë–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (backfill)\")\n",
    "print(\"      ‚Ä¢ Real-time dashboard (Streamlit/Dash)\")\n",
    "print(\"      ‚Ä¢ Predictive analytics (–ø—Ä–æ–≥–Ω–æ–∑—ã —Ü–µ–Ω)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
    "\n",
    "### üîç –ß—Ç–æ –º—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏:\n",
    "1. **–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä—ã–Ω–∫–∞** - —Ü–µ–Ω—ã, —Ç—Ä–µ–Ω–¥—ã, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\n",
    "2. **Sentiment –Ω–æ–≤–æ—Å—Ç–µ–π** - keyword-based –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è positive/negative/neutral\n",
    "3. **OHLC –ø–∞—Ç—Ç–µ—Ä–Ω—ã** - —Å–≤–µ—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑ —Å –æ–±—ä–µ–º–∞–º–∏\n",
    "4. **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏** - –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å —Ü–µ–Ω, –æ–±—ä–µ–º–æ–≤, sentiment\n",
    "5. **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã** - –¥–∏–Ω–∞–º–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–∞–Ω–Ω—ã–µ)\n",
    "6. **–°–≤–æ–¥–Ω–∞—è –ø–∞–Ω–µ–ª—å** - –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ\n",
    "\n",
    "### üìä 6 —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π:\n",
    "1. ‚úÖ **Snapshot —Ä—ã–Ω–∫–∞** (4 –≥—Ä–∞—Ñ–∏–∫–∞: —Ü–µ–Ω—ã, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, —Ç—Ä–µ–Ω–¥—ã, MA)\n",
    "2. ‚úÖ **Sentiment Distribution** (4 –≥—Ä–∞—Ñ–∏–∫–∞: pie chart, daily bars, box plot, scatter)\n",
    "3. ‚úÖ **Candlestick Chart** (OHLC + volume)\n",
    "4. ‚úÖ **Correlation Heatmap** (—Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞)\n",
    "5. ‚úÖ **Time Series** (price trends + news frequency)\n",
    "6. ‚úÖ **Summary Dashboard** (9 –º–∏–Ω–∏-–≥—Ä–∞—Ñ–∏–∫–æ–≤)\n",
    "\n",
    "### üéØ –ò–Ω—Å–∞–π—Ç—ã:\n",
    "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã –ø–æ –∫–∞–∂–¥–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "- –¢–æ—Ä–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "- –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "- –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—ã\n",
    "\n",
    "### üöÄ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:\n",
    "- **–°–±–æ—Ä**: FastAPI + Binance API + Crypto.news RSS\n",
    "- **–•—Ä–∞–Ω–µ–Ω–∏–µ**: MongoDB ‚Üí PostgreSQL 13\n",
    "- **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏**: DBT 1.8.7 (STG ‚Üí ODS ‚Üí DM)\n",
    "- **–ö–∞—á–µ—Å—Ç–≤–æ**: Elementary Data (57 —Ç–µ—Å—Ç–æ–≤)\n",
    "- **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è**: Airflow 2.10.5\n",
    "- **–ê–Ω–∞–ª–∏–∑**: Python + Pandas + Matplotlib + Seaborn\n",
    "\n",
    "–í—Å–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\n",
    "conn.close()\n",
    "print(\"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
